{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #6: Dependency parsing\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment is inspired by the CoNLL 2018 shared task of the conference on computational natural language learning on dependency parsing, http://universaldependencies.org/conll18/. It is a follower of <a href=\"http://ilk.uvt.nl/conll/\">CONLL-X</a>, which was the first large-scale evaluation of dependency parsers.\n",
    "            \n",
    "In this session, you will implement a dependency parser for Swedish and, optionally, for another language that you will choose.\n",
    "\n",
    "The objectives of this assignment are to:\n",
    "* Know what a dependency graph is\n",
    "* Understand the principles of a transition-based parser\n",
    "* Extend the parser with a guiding predicate that parses an annotated dependency graph\n",
    "* Extract features to learn parsing actions from an annotated corpus\n",
    "* Write a short report on your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organization and location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can work alone or collaborate with another student.\n",
    "Each group will have to:\n",
    "* Write a program that parses a sentence when the dependency graph is known\n",
    "* Extract features from the parsing actions.\n",
    "* Train a classifier\n",
    "* Apply it on a test corpus\n",
    "* Evaluate the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As corpora, you will use the Universal Dependencies: https://universaldependencies.org/. The corpora are the same that you used in the 5th assignment, but you will use the test set in addition to the training set. \n",
    "1. You will train your parser on training part of the Swedish _Talbanken_ corpus and you will evaluate it on the test set. \n",
    "2. Optionally, you will repeat the experiment with another language. \n",
    "3. You will comment your results in the report. \n",
    "\n",
    "You will load the corpora as in the 5th assignment and the next cells are just copies from this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the corpus locations you will use. You may have to adjust `ud_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ud_path = '../../corpus/ud-treebanks-v2.8/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_sv_train = ud_path + 'UD_Swedish-Talbanken/sv_talbanken-ud-train.conllu'\n",
    "path_sv_test = ud_path + 'UD_Swedish-Talbanken/sv_talbanken-ud-test.conllu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names of the CoNLL-U corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_u = ['ID', 'FORM', 'LEMMA', 'UPOS', 'XPOS', 'FEATS', 'HEAD', 'DEPREL', 'DEPS', 'MISC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to read the CoNLL-U files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(file):\n",
    "    \"\"\"\n",
    "    Creates a list of sentences from the corpus\n",
    "    Each sentence is a string\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = open(file, encoding='utf-8').read().strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(sentences, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    root_values = ['0', 'root', 'root', 'root', 'root', 'root', '0', 'root', 'root', 'root']\n",
    "    start = [dict(zip(column_names, root_values))]\n",
    "    for sentence in sentences:\n",
    "        rows = sentence.split('\\n')\n",
    "        sentence = [dict(zip(column_names, row.split('\\t'))) for row in rows if row[0] != '#']\n",
    "        sentence = start + sentence\n",
    "        new_sentences.append(sentence)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the Swedish _Talbanken_ corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = read_sentences(path_sv_train)\n",
    "formatted_corpus_train = split_rows(sentences, column_names_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4303"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(formatted_corpus_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parsed sentence: _Individuell beskattning av arbetsinkomster_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ID': '0',\n",
       "  'FORM': 'root',\n",
       "  'LEMMA': 'root',\n",
       "  'UPOS': 'root',\n",
       "  'XPOS': 'root',\n",
       "  'FEATS': 'root',\n",
       "  'HEAD': '0',\n",
       "  'DEPREL': 'root',\n",
       "  'DEPS': 'root',\n",
       "  'MISC': 'root'},\n",
       " {'ID': '1',\n",
       "  'FORM': 'Individuell',\n",
       "  'LEMMA': 'individuell',\n",
       "  'UPOS': 'ADJ',\n",
       "  'XPOS': 'JJ|POS|UTR|SIN|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Degree=Pos|Gender=Com|Number=Sing',\n",
       "  'HEAD': '2',\n",
       "  'DEPREL': 'amod',\n",
       "  'DEPS': '2:amod',\n",
       "  'MISC': '_'},\n",
       " {'ID': '2',\n",
       "  'FORM': 'beskattning',\n",
       "  'LEMMA': 'beskattning',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|SIN|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Gender=Com|Number=Sing',\n",
       "  'HEAD': '0',\n",
       "  'DEPREL': 'root',\n",
       "  'DEPS': '0:root',\n",
       "  'MISC': '_'},\n",
       " {'ID': '3',\n",
       "  'FORM': 'av',\n",
       "  'LEMMA': 'av',\n",
       "  'UPOS': 'ADP',\n",
       "  'XPOS': 'PP',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '4',\n",
       "  'DEPREL': 'case',\n",
       "  'DEPS': '4:case',\n",
       "  'MISC': '_'},\n",
       " {'ID': '4',\n",
       "  'FORM': 'arbetsinkomster',\n",
       "  'LEMMA': 'arbetsinkomst',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|PLU|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Gender=Com|Number=Plur',\n",
       "  'HEAD': '2',\n",
       "  'DEPREL': 'nmod',\n",
       "  'DEPS': '2:nmod:av',\n",
       "  'MISC': '_'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_corpus_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing indices that are not integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ease the processing of some corpora, we remove the indices which are not integers. We do this because `ID` is not necessarily a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_indicies(formatted_corpus):\n",
    "    formatted_corpus_clean = []\n",
    "    for sentence in formatted_corpus:\n",
    "        formatted_corpus_clean.append([word for word in sentence if word['ID'].isdigit()])\n",
    "    return formatted_corpus_clean          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ID': '0',\n",
       "  'FORM': 'root',\n",
       "  'LEMMA': 'root',\n",
       "  'UPOS': 'root',\n",
       "  'XPOS': 'root',\n",
       "  'FEATS': 'root',\n",
       "  'HEAD': '0',\n",
       "  'DEPREL': 'root',\n",
       "  'DEPS': 'root',\n",
       "  'MISC': 'root'},\n",
       " {'ID': '1',\n",
       "  'FORM': 'Individuell',\n",
       "  'LEMMA': 'individuell',\n",
       "  'UPOS': 'ADJ',\n",
       "  'XPOS': 'JJ|POS|UTR|SIN|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Degree=Pos|Gender=Com|Number=Sing',\n",
       "  'HEAD': '2',\n",
       "  'DEPREL': 'amod',\n",
       "  'DEPS': '2:amod',\n",
       "  'MISC': '_'},\n",
       " {'ID': '2',\n",
       "  'FORM': 'beskattning',\n",
       "  'LEMMA': 'beskattning',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|SIN|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Gender=Com|Number=Sing',\n",
       "  'HEAD': '0',\n",
       "  'DEPREL': 'root',\n",
       "  'DEPS': '0:root',\n",
       "  'MISC': '_'},\n",
       " {'ID': '3',\n",
       "  'FORM': 'av',\n",
       "  'LEMMA': 'av',\n",
       "  'UPOS': 'ADP',\n",
       "  'XPOS': 'PP',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '4',\n",
       "  'DEPREL': 'case',\n",
       "  'DEPS': '4:case',\n",
       "  'MISC': '_'},\n",
       " {'ID': '4',\n",
       "  'FORM': 'arbetsinkomster',\n",
       "  'LEMMA': 'arbetsinkomst',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|PLU|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Gender=Com|Number=Plur',\n",
       "  'HEAD': '2',\n",
       "  'DEPREL': 'nmod',\n",
       "  'DEPS': '2:nmod:av',\n",
       "  'MISC': '_'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_corpus_train_clean = clean_indicies(formatted_corpus_train)\n",
    "formatted_corpus_train_clean[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence with a projective dependency graph, there is an action sequence that enables the transition parser\n",
    "to generate this graph. Gold standard parsing corresponds to the sequence of parsing actions, left-arc (<tt>la</tt>), right-arc (<tt>ra</tt>), shift (<tt>sh</tt>), and reduce (<tt>re</tt>) that produces the manually-obtained, gold standard, graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are implementations of the parsing transitions. Read them and be sure you understand them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift(stack, queue, graph):\n",
    "    \"\"\"\n",
    "    Shift the first word in the queue onto the stack\n",
    "    :param stack:\n",
    "    :param queue:\n",
    "    :param graph:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    stack = [queue[0]] + stack\n",
    "    queue = queue[1:]\n",
    "    return stack, queue, graph\n",
    "\n",
    "\n",
    "def reduce(stack, queue, graph):\n",
    "    \"\"\"\n",
    "    Remove the first item from the stack\n",
    "    :param stack:\n",
    "    :param queue:\n",
    "    :param graph:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return stack[1:], queue, graph\n",
    "\n",
    "\n",
    "def right_arc(stack, queue, graph, deprel=False):\n",
    "    \"\"\"\n",
    "    Creates an arc from the top of the stack to the first in the queue\n",
    "    and shifts\n",
    "    The deprel argument is either read from the manually-annotated corpus\n",
    "    (deprel=False) or assigned by the parser. In this case, the deprel\n",
    "    argument has a value\n",
    "    :param stack:\n",
    "    :param queue:\n",
    "    :param graph:\n",
    "    :param deprel: either read from the manually-annotated corpus (value false)\n",
    "    or assigned by the parser\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    graph['heads'][queue[0]['ID']] = stack[0]['ID']\n",
    "    if deprel:\n",
    "        graph['deprels'][queue[0]['ID']] = deprel\n",
    "    else:\n",
    "        graph['deprels'][queue[0]['ID']] = queue[0]['DEPREL']\n",
    "    # If we create an arc from the 'root', we introduce a statement to pop it to avoid multiple roots\n",
    "    if stack[0]['ID'] == '0':\n",
    "        stack = stack[1:]\n",
    "    return shift(stack, queue, graph)\n",
    "\n",
    "\n",
    "def left_arc(stack, queue, graph, deprel=False):\n",
    "    \"\"\"\n",
    "    Creates an arc from the first in the queue to the top of the stack\n",
    "    and reduces it.\n",
    "    The deprel argument is either read from the manually-annotated corpus\n",
    "    (deprel=False) or assigned by the parser. In this case, the deprel\n",
    "    argument has a value\n",
    "    :param stack:\n",
    "    :param queue:\n",
    "    :param graph:\n",
    "    :param deprel: either read from the manually-annotated corpus (value false)\n",
    "    or assigned by the parser\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    graph['heads'][stack[0]['ID']] = queue[0]['ID']\n",
    "    if deprel:\n",
    "        graph['deprels'][stack[0]['ID']] = deprel\n",
    "    else:\n",
    "        graph['deprels'][stack[0]['ID']] = stack[0]['DEPREL']        \n",
    "    return reduce(stack, queue, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constrains on the transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a few constraints before we carry out the transitions. Given a manually-annotated dependency graph, look at the conditions (`can_...()` functions) on the stack and the current input list -- the queue -- to execute left-arc, right-arc, shift, or reduce. Read about these constrains in the slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def can_reduce(stack, graph):\n",
    "    \"\"\"\n",
    "    Checks that the top of the stack has a head\n",
    "    :param stack:\n",
    "    :param graph:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if not stack:\n",
    "        return False\n",
    "    if stack[0]['ID'] in graph['heads']:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    \n",
    "def can_leftarc(stack, graph):\n",
    "    \"\"\"\n",
    "    Checks that the top of the has no head\n",
    "    :param stack:\n",
    "    :param graph:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if not stack:\n",
    "        return False\n",
    "    if stack[0]['ID'] in graph['heads']:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def can_rightarc(stack):\n",
    "    \"\"\"\n",
    "    Simply checks there is a stack\n",
    "    :param stack:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if not stack:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the transitions from a manually-parsed sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using an annotated corpus, we can derive the action sequences producing the manually-parsed sentences (provided that they are projective). We use an oracle for this as explained during the lectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracle(stack, queue, graph):\n",
    "    \"\"\"\n",
    "    Gold standard parsing\n",
    "    Produces a sequence of transitions from a manually-annotated corpus:\n",
    "    sh, re, ra.deprel, la.deprel\n",
    "    :param stack: The stack\n",
    "    :param queue: The input list\n",
    "    :param graph: The set of relations already parsed\n",
    "    :return: the transition and the grammatical function (deprel) in the\n",
    "    form of transition.deprel\n",
    "    \"\"\"\n",
    "    # Right arc\n",
    "    if stack and stack[0]['ID'] == queue[0]['HEAD']:\n",
    "        # print('ra', queue[0]['DEPREL'], stack[0]['UPOS'], queue[0]['UPOS'])\n",
    "        deprel = '.' + queue[0]['DEPREL']\n",
    "        stack, queue, graph = right_arc(stack, queue, graph)\n",
    "        return stack, queue, graph, 'ra' + deprel\n",
    "    # Left arc\n",
    "    if stack and queue[0]['ID'] == stack[0]['HEAD']:\n",
    "        # print('la', stack[0]['DEPREL'], stack[0]['UPOS'], queue[0]['UPOS'])\n",
    "        deprel = '.' + stack[0]['DEPREL']\n",
    "        stack, queue, graph = left_arc(stack, queue, graph)\n",
    "        return stack, queue, graph, 'la' + deprel\n",
    "    # Reduce\n",
    "    if stack and can_reduce(stack, graph):\n",
    "        for word in stack:\n",
    "            if (word['ID'] == queue[0]['HEAD'] or\n",
    "                    word['HEAD'] == queue[0]['ID']):\n",
    "                # print('re', stack[0]['UPOS'], queue[0]['UPOS'])\n",
    "                stack, queue, graph = reduce(stack, queue, graph)\n",
    "                return stack, queue, graph, 're'\n",
    "    # Shift\n",
    "    # print('sh', [], queue[0]['UPOS'])\n",
    "    stack, queue, graph = shift(stack, queue, graph)\n",
    "    return stack, queue, graph, 'sh'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with nonprojective graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oracle parsing produces a sequence of transitions if the graph is projective and well-formed. If not, we will have headless words in the stack. Parsing normally terminates when the queue is empty. We also empty the stack to be sure that all the words have a head. We attach headless words to the root word of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists_root(graph):\n",
    "    for (x, y)  in graph['heads'].items():\n",
    "        if y == '0' and x != '0':\n",
    "            return x\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_stack(stack, graph):\n",
    "    \"\"\"\n",
    "    Pops the items in the stack. If they have no head, they are assigned\n",
    "    a ROOT head\n",
    "    :param stack:\n",
    "    :param graph:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    idx_root = exists_root(graph)\n",
    "    # There is already a root\n",
    "    if idx_root:\n",
    "        for word in stack:\n",
    "            if word['ID'] not in graph['heads']:\n",
    "                graph['heads'][word['ID']] = idx_root\n",
    "                graph['deprels'][word['ID']] = 'dep'\n",
    "    else:\n",
    "        # There is no root. We assign the root to the first headless word.\n",
    "        for word in stack:\n",
    "            if word['ID'] not in graph['heads']:\n",
    "                if idx_root:\n",
    "                    graph['heads'][word['ID']] = idx_root\n",
    "                    graph['deprels'][word['ID']] = 'dep'\n",
    "                else:\n",
    "                    graph['heads'][word['ID']] = '0'\n",
    "                    graph['deprels'][word['ID']] = 'root'\n",
    "                    idx_root = word['ID']\n",
    "    stack = []\n",
    "    return stack, graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if two graphs are equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `equal_graphs()` utility checks if the graph obtained from a sequence of transitions is equal to the annotated graph. It is normally the case, except with nonprojective graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_graphs(sentence, graph, verbose=False):\n",
    "    \"\"\"\n",
    "    Checks that the graph corresponds to the gold standard annotation of a sentence\n",
    "    :param sentence:\n",
    "    :param graph:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    equal = True\n",
    "    for word in sentence:\n",
    "        if word['ID'] in graph['heads'] and word['HEAD'] == graph['heads'][word['ID']]:\n",
    "            pass\n",
    "        else:\n",
    "            equal = False\n",
    "            if verbose:\n",
    "                print(word, flush=True)\n",
    "    return equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing an annotated corpus with an oracle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now run the code below. With it, you will produce a sequence of transitions for each sentence. If the graph is projective, applying the sequence to the sentence will recreate the gold-standard annotation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experiment:\n",
    "1. Understand from the slides used during the lecture how the oracle carries out a gold-standard parsing. \n",
    "2. The parser can only deal with projective sentences. In the case of a nonprojective one, the parsed graph and the manually-annotated sentence are not equal. Select one nonprojective sentence (just set `verbose`to `True` in the code below) and examine it. \n",
    "3. In your report, you will include one short nonprojective sentence (choose the shortest). You will  **describe** it in the report and you will explain why it is not projective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_config(sentence):\n",
    "    stack = []\n",
    "    queue = list(sentence)\n",
    "    graph = {}\n",
    "    graph['heads'] = {}\n",
    "    graph['heads']['0'] = '0'\n",
    "    graph['deprels'] = {}\n",
    "    graph['deprels']['0'] = 'ROOT'\n",
    "    return stack, queue, graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 4302 sentences\n"
     ]
    }
   ],
   "source": [
    "verbose = False\n",
    "projectivization = False\n",
    "\n",
    "transition_corpus = []\n",
    "graph_corpus = []\n",
    "\n",
    "for sent_cnt, sentence in enumerate(formatted_corpus_train_clean):\n",
    "    #print(sentence)\n",
    "    stack, queue, graph = init_config(sentence)\n",
    "    transition_sent = []\n",
    "    while queue:\n",
    "        stack, queue, graph, trans = oracle(stack, queue, graph)\n",
    "        transition_sent.append(trans)\n",
    "    stack, graph = empty_stack(stack, graph)\n",
    "    transition_corpus.append(transition_sent)\n",
    "    graph_corpus.append(graph)\n",
    "\n",
    "    if verbose:\n",
    "        if not equal_graphs(sentence, graph):\n",
    "            print('Annotation and gold-standard parsing not equal')\n",
    "            print('Sentence:', sentence)\n",
    "            print('Gold-standard graph', graph)\n",
    "    # Poorman's projectivization to have well-formed graphs.\n",
    "    # We just just assign the same heads as what gold standard parsing did\n",
    "    # This guarantee a projective sentence\n",
    "    if projectivization:\n",
    "        for word in sentence:\n",
    "            word['HEAD'] = graph['heads'][word['ID']]\n",
    "print('\\nProcessed ' + str(sent_cnt) + ' sentences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking gold-standard parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply manually the transition sequence you obtained to the first sentence and check that it parses it correctly. You will draw a stack and a queue with **seven steps** and you will describe this in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'ID': '0',\n",
       "   'FORM': 'root',\n",
       "   'LEMMA': 'root',\n",
       "   'UPOS': 'root',\n",
       "   'XPOS': 'root',\n",
       "   'FEATS': 'root',\n",
       "   'HEAD': '0',\n",
       "   'DEPREL': 'root',\n",
       "   'DEPS': 'root',\n",
       "   'MISC': 'root'},\n",
       "  {'ID': '1',\n",
       "   'FORM': 'Individuell',\n",
       "   'LEMMA': 'individuell',\n",
       "   'UPOS': 'ADJ',\n",
       "   'XPOS': 'JJ|POS|UTR|SIN|IND|NOM',\n",
       "   'FEATS': 'Case=Nom|Definite=Ind|Degree=Pos|Gender=Com|Number=Sing',\n",
       "   'HEAD': '2',\n",
       "   'DEPREL': 'amod',\n",
       "   'DEPS': '2:amod',\n",
       "   'MISC': '_'},\n",
       "  {'ID': '2',\n",
       "   'FORM': 'beskattning',\n",
       "   'LEMMA': 'beskattning',\n",
       "   'UPOS': 'NOUN',\n",
       "   'XPOS': 'NN|UTR|SIN|IND|NOM',\n",
       "   'FEATS': 'Case=Nom|Definite=Ind|Gender=Com|Number=Sing',\n",
       "   'HEAD': '0',\n",
       "   'DEPREL': 'root',\n",
       "   'DEPS': '0:root',\n",
       "   'MISC': '_'},\n",
       "  {'ID': '3',\n",
       "   'FORM': 'av',\n",
       "   'LEMMA': 'av',\n",
       "   'UPOS': 'ADP',\n",
       "   'XPOS': 'PP',\n",
       "   'FEATS': '_',\n",
       "   'HEAD': '4',\n",
       "   'DEPREL': 'case',\n",
       "   'DEPS': '4:case',\n",
       "   'MISC': '_'},\n",
       "  {'ID': '4',\n",
       "   'FORM': 'arbetsinkomster',\n",
       "   'LEMMA': 'arbetsinkomst',\n",
       "   'UPOS': 'NOUN',\n",
       "   'XPOS': 'NN|UTR|PLU|IND|NOM',\n",
       "   'FEATS': 'Case=Nom|Definite=Ind|Gender=Com|Number=Plur',\n",
       "   'HEAD': '2',\n",
       "   'DEPREL': 'nmod',\n",
       "   'DEPS': '2:nmod:av',\n",
       "   'MISC': '_'}]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_corpus_train_clean[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sh', 'sh', 'la.amod', 'ra.root', 'sh', 'la.case', 'ra.nmod']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_corpus[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'heads': {'0': '0', '1': '2', '2': '0', '3': '4', '4': '2'},\n",
       "  'deprels': {'0': 'ROOT',\n",
       "   '1': 'amod',\n",
       "   '2': 'root',\n",
       "   '3': 'case',\n",
       "   '4': 'nmod'}}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_corpus[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train a classifier to predict an action from a current parsing context. To be able to predict the next action from a given parsing state, gold-standard parsing must also extract feature vectors at each step of the parsing procedure. The simplest parsing context corresponds to the words' part of speech on the top of the stack and the first of the input list (the queue).\n",
    "    \n",
    "Once the data collected, the training procedure will produce a 4-class classifier that you will embed in\n",
    "Nivre's parser to choose the next action. During parsing, Nivre's parser will call the classifier to choose\n",
    "the next action in the set {`la`, `ra`, `sh`, `re`} using the current context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use two feature sets to build your models:\n",
    "1. The top of the stack and the first word of the input list (word forms and parts of speech);\n",
    "2. The two first words and POS on the top of the stack and the two first words and POS of the input list;\n",
    "\n",
    "You will also add constraints to actions. You will encode these constraints as Boolean features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the grammatical functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the actions in the set {`la`, `ra`, `sh`, `re`} produces an unlabelled\n",
    "graph. It is easy to extend the parser so that it can label the graph with grammatical functions. In this\n",
    "case, we must complement the actions `la` and `ra` with their function using a notation, `action.function`, where the prefix is the action and the suffix is the function, for example:`la.mod`, `la.case`, `ra.nmod`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final goal is to parse the Swedish corpus and produce a labelled dependency graph. \n",
    "\n",
    "You will train two models with logistic regression using scikit-learn. The two feature sets are:\n",
    "1. The first set will use the word and the part of speech extracted from the first element in the stack and the first in the queue,\n",
    "2. the second one will use two elements from the stack and two from the input list (word and part of speech).\n",
    "\n",
    "These sets will include two additional Boolean parameters, \"can do left arc\" and \"can do reduce\", which will model constraints on the parser's actions. In total, the feature sets will then have six, respectively ten parameters.\n",
    "\n",
    "This means that the purpose of this assignment is to generate two scikit-learn models for the labelled graphs. We use the depth parameter for this: The depth of the stack and the queue, either 1 or 2. Start with 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need the `queue_stack()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queue_stack(queue_or_stack, graph, depth, pos=True, lex=True):\n",
    "    features = []\n",
    "    features_pos = ['nil'] * depth\n",
    "    features_lex = ['nil'] * depth\n",
    "    features_deprel = ['nil'] * depth\n",
    "    if queue_or_stack:\n",
    "        for i, word in list(enumerate(queue_or_stack))[:depth]:\n",
    "            features_pos[i] = queue_or_stack[i]['UPOS']\n",
    "            features_lex[i] = queue_or_stack[i]['FORM']\n",
    "    if pos:\n",
    "        features += features_pos\n",
    "    if lex:\n",
    "        features += features_lex\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, you may want to extend the feature vector with words to the left of the top of the stack with the `right_context()` function. If the top of the stack has index $i$, you will extract the words and their parts of speech at index $i + 1$, $i+2$. This will noticeably improve the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def right_context(stack, sentence, depth, pos=True, lex=True):\n",
    "    features = []\n",
    "    features_pos = ['nil'] * depth\n",
    "    features_lex = ['nil'] * depth\n",
    "    if stack:\n",
    "        fw_id = int(stack[0]['ID']) + 1\n",
    "        for i, word in list(enumerate(sentence))[fw_id: fw_id + depth]:\n",
    "            features_pos[i - fw_id] = sentence[i]['UPOS']\n",
    "            features_lex[i - fw_id] = sentence[i]['FORM']\n",
    "    if pos:\n",
    "        features += features_pos\n",
    "    if lex:\n",
    "        features += features_lex\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function returns the features in a dictionary format compatible with scikit-learn. You have a code example of feature encoding in this format in the chunking program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(depth, stack, queue, graph, sentence):\n",
    "    \"\"\"\n",
    "    :param stack:\n",
    "    :param queue:\n",
    "    :param graph:\n",
    "    :param feature_names:\n",
    "    :param sentence:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    improved = True\n",
    "    if improved:\n",
    "        x = (queue_stack(stack, graph, depth) +\n",
    "             queue_stack(queue, graph, depth) +\n",
    "             right_context(stack, sentence, depth) +\n",
    "             [can_reduce(stack, graph), can_leftarc(stack, graph)])\n",
    "    else:\n",
    "        x = (queue_stack(stack, graph, depth) +\n",
    "             queue_stack(queue, graph, depth) +\n",
    "             [can_reduce(stack, graph), can_leftarc(stack, graph)])     \n",
    "    feature_names = ['feat' + str(i) for i in range(len(x))]\n",
    "    features = dict(zip(feature_names, x))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now write a loop to parse the annotated corpus using the oracle and collect the features in a matrix ($\\mathbf{X}$) and the transitions in a vector ($\\mathbf{y}$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first lines of your features for the 4 parameters ($\\mathbf{x}$) and labelled actions ($y$) should look like the excerpt below, where the columns correspond to stack0_POS, stack1_POS, stack0_word, stack1_word, queue0_POS, queue1_POS, queue0_word, queue1_word, can-re, can-la, and the transition value (`depth = 2`):\n",
    "$\\mathbf{X} =\n",
    "\\begin{bmatrix}\n",
    "\\text{nil}& \\text{nil} &\\text{nil} & \\text{nil} & \\text{ROOT} & \\text{ADJ} & \\text{ROOT} & \\text{Individuell} & \\text{False} & \\text{False}\\\\\n",
    "\\text{ROOT} &     \\text{nil} &     \\text{ROOT} &     \\text{nil} &     \\text{ADJ} &     \\text{NOUN} &     \\text{Individuell} &     \\text{beskattning} &     \\text{True} &     \\text{False}\\\\ \n",
    "\\text{ADJ} &     \\text{ROOT} &     \\text{Individuell} &     \\text{ROOT} &     \\text{NOUN} &     \\text{ADP} &     \\text{beskattning} &     \\text{av} &     \\text{False} &     \\text{True}\\\\ \n",
    "\\text{ROOT} &     \\text{nil} &     \\text{ROOT} &     \\text{nil} &     \\text{NOUN} &     \\text{ADP} &     \\text{beskattning} &     \\text{av} &     \\text{True} &     \\text{False}\\\\\n",
    "\\text{NOUN} &     \\text{ROOT} &     \\text{beskattning} &     \\text{ROOT} &     \\text{ADP} &     \\text{NOUN} &     \\text{av} &     \\text{arbetsinkomster} &     \\text{True} &     \\text{False}\\\\\n",
    "\\text{ADP} &     \\text{NOUN} &     \\text{av} &     \\text{beskattning} &     \\text{NOUN} &     \\text{nil} &     \\text{arbetsinkomster} &     \\text{nil} &     \\text{False} &     \\text{True}\\\\  \\text{NOUN} &     \\text{ROOT} &     \\text{beskattning} &     \\text{ROOT} &     \\text{NOUN} &     \\text{nil} &     \\text{arbetsinkomster} &     \\text{nil} &     \\text{True} &  \\text{False}\n",
    "\\end{bmatrix}$\n",
    "; $\\mathbf{y} =\n",
    "\\begin{bmatrix}\n",
    "\\text{sh}\\\\\n",
    "\\text{sh}\\\\\n",
    "\\text{la.amod}\\\\\n",
    "\\text{ra.root}\\\\\n",
    "\\text{sh}\\\\\n",
    "\\text{la.case}\\\\\n",
    "\\text{ra.nmod}\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will store your matrix in a list of Python dictionaries and the classes in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dict = []\n",
    "y_symbols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the features...\n",
      "0 sentences on 4303\n",
      "1000 sentences on 4303\n",
      "2000 sentences on 4303\n",
      "3000 sentences on 4303\n",
      "4000 sentences on 4303\n",
      "Extracting the features: Done\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feat0': 'nil',\n",
       "  'feat1': 'nil',\n",
       "  'feat2': 'nil',\n",
       "  'feat3': 'nil',\n",
       "  'feat4': 'root',\n",
       "  'feat5': 'ADJ',\n",
       "  'feat6': 'root',\n",
       "  'feat7': 'Individuell',\n",
       "  'feat8': 'nil',\n",
       "  'feat9': 'nil',\n",
       "  'feat10': 'nil',\n",
       "  'feat11': 'nil',\n",
       "  'feat12': False,\n",
       "  'feat13': False},\n",
       " {'feat0': 'root',\n",
       "  'feat1': 'nil',\n",
       "  'feat2': 'root',\n",
       "  'feat3': 'nil',\n",
       "  'feat4': 'ADJ',\n",
       "  'feat5': 'NOUN',\n",
       "  'feat6': 'Individuell',\n",
       "  'feat7': 'beskattning',\n",
       "  'feat8': 'ADJ',\n",
       "  'feat9': 'NOUN',\n",
       "  'feat10': 'Individuell',\n",
       "  'feat11': 'beskattning',\n",
       "  'feat12': True,\n",
       "  'feat13': False},\n",
       " {'feat0': 'ADJ',\n",
       "  'feat1': 'root',\n",
       "  'feat2': 'Individuell',\n",
       "  'feat3': 'root',\n",
       "  'feat4': 'NOUN',\n",
       "  'feat5': 'ADP',\n",
       "  'feat6': 'beskattning',\n",
       "  'feat7': 'av',\n",
       "  'feat8': 'NOUN',\n",
       "  'feat9': 'ADP',\n",
       "  'feat10': 'beskattning',\n",
       "  'feat11': 'av',\n",
       "  'feat12': False,\n",
       "  'feat13': True},\n",
       " {'feat0': 'root',\n",
       "  'feat1': 'nil',\n",
       "  'feat2': 'root',\n",
       "  'feat3': 'nil',\n",
       "  'feat4': 'NOUN',\n",
       "  'feat5': 'ADP',\n",
       "  'feat6': 'beskattning',\n",
       "  'feat7': 'av',\n",
       "  'feat8': 'ADJ',\n",
       "  'feat9': 'NOUN',\n",
       "  'feat10': 'Individuell',\n",
       "  'feat11': 'beskattning',\n",
       "  'feat12': True,\n",
       "  'feat13': False},\n",
       " {'feat0': 'NOUN',\n",
       "  'feat1': 'nil',\n",
       "  'feat2': 'beskattning',\n",
       "  'feat3': 'nil',\n",
       "  'feat4': 'ADP',\n",
       "  'feat5': 'NOUN',\n",
       "  'feat6': 'av',\n",
       "  'feat7': 'arbetsinkomster',\n",
       "  'feat8': 'ADP',\n",
       "  'feat9': 'NOUN',\n",
       "  'feat10': 'av',\n",
       "  'feat11': 'arbetsinkomster',\n",
       "  'feat12': True,\n",
       "  'feat13': False},\n",
       " {'feat0': 'ADP',\n",
       "  'feat1': 'NOUN',\n",
       "  'feat2': 'av',\n",
       "  'feat3': 'beskattning',\n",
       "  'feat4': 'NOUN',\n",
       "  'feat5': 'nil',\n",
       "  'feat6': 'arbetsinkomster',\n",
       "  'feat7': 'nil',\n",
       "  'feat8': 'NOUN',\n",
       "  'feat9': 'nil',\n",
       "  'feat10': 'arbetsinkomster',\n",
       "  'feat11': 'nil',\n",
       "  'feat12': False,\n",
       "  'feat13': True},\n",
       " {'feat0': 'NOUN',\n",
       "  'feat1': 'nil',\n",
       "  'feat2': 'beskattning',\n",
       "  'feat3': 'nil',\n",
       "  'feat4': 'NOUN',\n",
       "  'feat5': 'nil',\n",
       "  'feat6': 'arbetsinkomster',\n",
       "  'feat7': 'nil',\n",
       "  'feat8': 'ADP',\n",
       "  'feat9': 'NOUN',\n",
       "  'feat10': 'av',\n",
       "  'feat11': 'arbetsinkomster',\n",
       "  'feat12': True,\n",
       "  'feat13': False}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dict[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sh', 'sh', 'la.amod', 'ra.root', 'sh', 'la.case', 'ra.nmod']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_symbols[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the two scikit-learn models using the code models from the chunking labs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize your `X_dict` into an `X` matrix using `DictVectorizer()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model. With sklearn, you can use `y_symbols` directly. Use `verbose=True` and `n_jobs=8` or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =      4964205     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.43871D+05    |proj g|=  3.87624D+04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  4.10569D+04    |proj g|=  2.74268D+02\n",
      "\n",
      "At iterate  100    f=  3.18796D+04    |proj g|=  5.35013D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "*****    100    108      1     0     0   5.350D+01   3.188D+04\n",
      "  F =   31879.614198967178     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done   1 out of   1 | elapsed:  1.9min finished\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use this model to predict the sentences in the test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ID': '0',\n",
       "  'FORM': 'root',\n",
       "  'LEMMA': 'root',\n",
       "  'UPOS': 'root',\n",
       "  'XPOS': 'root',\n",
       "  'FEATS': 'root',\n",
       "  'HEAD': '0',\n",
       "  'DEPREL': 'root',\n",
       "  'DEPS': 'root',\n",
       "  'MISC': 'root'},\n",
       " {'ID': '1',\n",
       "  'FORM': 'Den',\n",
       "  'LEMMA': 'en',\n",
       "  'UPOS': 'DET',\n",
       "  'XPOS': 'DT|UTR|SIN|DEF',\n",
       "  'FEATS': 'Definite=Def|Gender=Com|Number=Sing|PronType=Art',\n",
       "  'HEAD': '3',\n",
       "  'DEPREL': 'det',\n",
       "  'DEPS': '3:det',\n",
       "  'MISC': '_'},\n",
       " {'ID': '2',\n",
       "  'FORM': 'allmänna',\n",
       "  'LEMMA': 'allmän',\n",
       "  'UPOS': 'ADJ',\n",
       "  'XPOS': 'JJ|POS|UTR/NEU|SIN|DEF|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Def|Degree=Pos|Number=Sing',\n",
       "  'HEAD': '3',\n",
       "  'DEPREL': 'amod',\n",
       "  'DEPS': '3:amod',\n",
       "  'MISC': '_'},\n",
       " {'ID': '3',\n",
       "  'FORM': 'pensionen',\n",
       "  'LEMMA': 'pension',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|SIN|DEF|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Def|Gender=Com|Number=Sing',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'nsubj',\n",
       "  'DEPS': '7:nsubj',\n",
       "  'MISC': '_'},\n",
       " {'ID': '4',\n",
       "  'FORM': 'är',\n",
       "  'LEMMA': 'vara',\n",
       "  'UPOS': 'AUX',\n",
       "  'XPOS': 'VB|PRS|AKT',\n",
       "  'FEATS': 'Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'cop',\n",
       "  'DEPS': '7:cop',\n",
       "  'MISC': '_'},\n",
       " {'ID': '5',\n",
       "  'FORM': 'av',\n",
       "  'LEMMA': 'av',\n",
       "  'UPOS': 'ADP',\n",
       "  'XPOS': 'PP',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'case',\n",
       "  'DEPS': '7:case',\n",
       "  'MISC': '_'},\n",
       " {'ID': '6',\n",
       "  'FORM': 'två',\n",
       "  'LEMMA': 'två',\n",
       "  'UPOS': 'NUM',\n",
       "  'XPOS': 'RG|NOM',\n",
       "  'FEATS': 'Case=Nom|NumType=Card',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'nummod',\n",
       "  'DEPS': '7:nummod',\n",
       "  'MISC': '_'},\n",
       " {'ID': '7',\n",
       "  'FORM': 'slag',\n",
       "  'LEMMA': 'slag',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|NEU|PLU|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Gender=Neut|Number=Plur',\n",
       "  'HEAD': '0',\n",
       "  'DEPREL': 'root',\n",
       "  'DEPS': '0:root',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " {'ID': '8',\n",
       "  'FORM': ':',\n",
       "  'LEMMA': ':',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': 'MID',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '7:punct',\n",
       "  'MISC': '_'},\n",
       " {'ID': '9',\n",
       "  'FORM': 'folkpension',\n",
       "  'LEMMA': 'folkpension',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|SIN|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Gender=Com|Number=Sing',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'appos',\n",
       "  'DEPS': '7:appos',\n",
       "  'MISC': '_'},\n",
       " {'ID': '10',\n",
       "  'FORM': 'och',\n",
       "  'LEMMA': 'och',\n",
       "  'UPOS': 'CCONJ',\n",
       "  'XPOS': 'KN',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '11',\n",
       "  'DEPREL': 'cc',\n",
       "  'DEPS': '11:cc',\n",
       "  'MISC': '_'},\n",
       " {'ID': '11',\n",
       "  'FORM': 'tilläggspension',\n",
       "  'LEMMA': 'tilläggspension',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|SIN|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Gender=Com|Number=Sing',\n",
       "  'HEAD': '9',\n",
       "  'DEPREL': 'conj',\n",
       "  'DEPS': '7:appos|9:conj:och',\n",
       "  'MISC': '_'},\n",
       " {'ID': '12',\n",
       "  'FORM': '(',\n",
       "  'LEMMA': '(',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': 'PAD',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '11',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '11:punct',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " {'ID': '13',\n",
       "  'FORM': 'ATP',\n",
       "  'LEMMA': 'ATP',\n",
       "  'UPOS': 'PROPN',\n",
       "  'XPOS': 'PM|NOM',\n",
       "  'FEATS': 'Case=Nom',\n",
       "  'HEAD': '11',\n",
       "  'DEPREL': 'appos',\n",
       "  'DEPS': '11:appos',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " {'ID': '14',\n",
       "  'FORM': ')',\n",
       "  'LEMMA': ')',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': 'PAD',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '11',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '11:punct',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " {'ID': '15',\n",
       "  'FORM': '.',\n",
       "  'LEMMA': '.',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': 'MAD',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '7:punct',\n",
       "  'MISC': '_'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_test = read_sentences(path_sv_test)\n",
    "formatted_corpus_test = split_rows(sentences_test, column_names_u)\n",
    "formatted_corpus_test_clean = clean_indicies(formatted_corpus_test)\n",
    "formatted_corpus_test_clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transition(stack, queue, graph, trans):\n",
    "    if stack and trans[:2] == 'ra':\n",
    "        stack, queue, graph = right_arc(stack, queue, graph, trans[3:])\n",
    "        return stack, queue, graph, 'ra'\n",
    "    if stack and can_leftarc(stack, graph) and trans[:2] == 'la':\n",
    "        if trans[3:] == 'root' and exists_root(graph):\n",
    "            stack, queue, graph = shift(stack, queue, graph)\n",
    "            return stack, queue, graph, 'sh'\n",
    "        else:\n",
    "            stack, queue, graph = left_arc(stack, queue, graph, trans[3:])\n",
    "            return stack, queue, graph, 'la'\n",
    "    if stack and can_reduce(stack, graph) and trans == 're':\n",
    "        stack, queue, graph = reduce(stack, queue, graph)\n",
    "        return stack, queue, graph, 're'\n",
    "    stack, queue, graph = shift(stack, queue, graph)\n",
    "    return stack, queue, graph, 'sh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████▋                      | 540/1219 [04:28<05:57,  1.90it/s]/Users/pierre/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|███████████████████████████████████████| 1219/1219 [10:58<00:00,  1.85it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for sent_cnt, sentence in enumerate(tqdm(formatted_corpus_test_clean)):\n",
    "    X_test_dict = []\n",
    "    stack, queue, graph = init_config(sentence)\n",
    "    while queue:\n",
    "        X_test_dict = extract(depth, stack, queue, graph, sentence)\n",
    "        X_test = vec.transform(X_test_dict)\n",
    "        y_test = classifier.predict(X_test)[0]\n",
    "        stack, queue, graph, trans = apply_transition(stack, queue, graph, y_test)\n",
    "    stack, graph = empty_stack(stack, graph)\n",
    "    for word in sentence:\n",
    "        word['HEAD'] = graph['heads'][word['ID']]\n",
    "        word['DEPREL'] = graph['deprels'][word['ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ID': '0',\n",
       "  'FORM': 'root',\n",
       "  'LEMMA': 'root',\n",
       "  'UPOS': 'root',\n",
       "  'XPOS': 'root',\n",
       "  'FEATS': 'root',\n",
       "  'HEAD': '0',\n",
       "  'DEPREL': 'ROOT',\n",
       "  'DEPS': 'root',\n",
       "  'MISC': 'root'},\n",
       " {'ID': '1',\n",
       "  'FORM': 'Den',\n",
       "  'LEMMA': 'en',\n",
       "  'UPOS': 'DET',\n",
       "  'XPOS': 'DT|UTR|SIN|DEF',\n",
       "  'FEATS': 'Definite=Def|Gender=Com|Number=Sing|PronType=Art',\n",
       "  'HEAD': '3',\n",
       "  'DEPREL': 'det',\n",
       "  'DEPS': '3:det',\n",
       "  'MISC': '_'},\n",
       " {'ID': '2',\n",
       "  'FORM': 'allmänna',\n",
       "  'LEMMA': 'allmän',\n",
       "  'UPOS': 'ADJ',\n",
       "  'XPOS': 'JJ|POS|UTR/NEU|SIN|DEF|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Def|Degree=Pos|Number=Sing',\n",
       "  'HEAD': '3',\n",
       "  'DEPREL': 'amod',\n",
       "  'DEPS': '3:amod',\n",
       "  'MISC': '_'},\n",
       " {'ID': '3',\n",
       "  'FORM': 'pensionen',\n",
       "  'LEMMA': 'pension',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|SIN|DEF|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Def|Gender=Com|Number=Sing',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'nsubj',\n",
       "  'DEPS': '7:nsubj',\n",
       "  'MISC': '_'},\n",
       " {'ID': '4',\n",
       "  'FORM': 'är',\n",
       "  'LEMMA': 'vara',\n",
       "  'UPOS': 'AUX',\n",
       "  'XPOS': 'VB|PRS|AKT',\n",
       "  'FEATS': 'Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'cop',\n",
       "  'DEPS': '7:cop',\n",
       "  'MISC': '_'},\n",
       " {'ID': '5',\n",
       "  'FORM': 'av',\n",
       "  'LEMMA': 'av',\n",
       "  'UPOS': 'ADP',\n",
       "  'XPOS': 'PP',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'case',\n",
       "  'DEPS': '7:case',\n",
       "  'MISC': '_'},\n",
       " {'ID': '6',\n",
       "  'FORM': 'två',\n",
       "  'LEMMA': 'två',\n",
       "  'UPOS': 'NUM',\n",
       "  'XPOS': 'RG|NOM',\n",
       "  'FEATS': 'Case=Nom|NumType=Card',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'nummod',\n",
       "  'DEPS': '7:nummod',\n",
       "  'MISC': '_'},\n",
       " {'ID': '7',\n",
       "  'FORM': 'slag',\n",
       "  'LEMMA': 'slag',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|NEU|PLU|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Gender=Neut|Number=Plur',\n",
       "  'HEAD': '0',\n",
       "  'DEPREL': 'root',\n",
       "  'DEPS': '0:root',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " {'ID': '8',\n",
       "  'FORM': ':',\n",
       "  'LEMMA': ':',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': 'MID',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '7:punct',\n",
       "  'MISC': '_'},\n",
       " {'ID': '9',\n",
       "  'FORM': 'folkpension',\n",
       "  'LEMMA': 'folkpension',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|SIN|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Gender=Com|Number=Sing',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'appos',\n",
       "  'DEPS': '7:appos',\n",
       "  'MISC': '_'},\n",
       " {'ID': '10',\n",
       "  'FORM': 'och',\n",
       "  'LEMMA': 'och',\n",
       "  'UPOS': 'CCONJ',\n",
       "  'XPOS': 'KN',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '11',\n",
       "  'DEPREL': 'cc',\n",
       "  'DEPS': '11:cc',\n",
       "  'MISC': '_'},\n",
       " {'ID': '11',\n",
       "  'FORM': 'tilläggspension',\n",
       "  'LEMMA': 'tilläggspension',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|SIN|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Gender=Com|Number=Sing',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'appos',\n",
       "  'DEPS': '7:appos|9:conj:och',\n",
       "  'MISC': '_'},\n",
       " {'ID': '12',\n",
       "  'FORM': '(',\n",
       "  'LEMMA': '(',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': 'PAD',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '11:punct',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " {'ID': '13',\n",
       "  'FORM': 'ATP',\n",
       "  'LEMMA': 'ATP',\n",
       "  'UPOS': 'PROPN',\n",
       "  'XPOS': 'PM|NOM',\n",
       "  'FEATS': 'Case=Nom',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'appos',\n",
       "  'DEPS': '11:appos',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " {'ID': '14',\n",
       "  'FORM': ')',\n",
       "  'LEMMA': ')',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': 'PAD',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '11:punct',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " {'ID': '15',\n",
       "  'FORM': '.',\n",
       "  'LEMMA': '.',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': 'MAD',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '7:punct',\n",
       "  'MISC': '_'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_corpus_test_clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ID': '0',\n",
       "  'FORM': 'root',\n",
       "  'LEMMA': 'root',\n",
       "  'UPOS': 'root',\n",
       "  'XPOS': 'root',\n",
       "  'FEATS': 'root',\n",
       "  'HEAD': '0',\n",
       "  'DEPREL': 'ROOT',\n",
       "  'DEPS': 'root',\n",
       "  'MISC': 'root'},\n",
       " {'ID': '1',\n",
       "  'FORM': 'Den',\n",
       "  'LEMMA': 'en',\n",
       "  'UPOS': 'DET',\n",
       "  'XPOS': 'DT|UTR|SIN|DEF',\n",
       "  'FEATS': 'Definite=Def|Gender=Com|Number=Sing|PronType=Art',\n",
       "  'HEAD': '3',\n",
       "  'DEPREL': 'det',\n",
       "  'DEPS': '3:det',\n",
       "  'MISC': '_'},\n",
       " {'ID': '2',\n",
       "  'FORM': 'allmänna',\n",
       "  'LEMMA': 'allmän',\n",
       "  'UPOS': 'ADJ',\n",
       "  'XPOS': 'JJ|POS|UTR/NEU|SIN|DEF|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Def|Degree=Pos|Number=Sing',\n",
       "  'HEAD': '3',\n",
       "  'DEPREL': 'amod',\n",
       "  'DEPS': '3:amod',\n",
       "  'MISC': '_'},\n",
       " {'ID': '3',\n",
       "  'FORM': 'pensionen',\n",
       "  'LEMMA': 'pension',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|SIN|DEF|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Def|Gender=Com|Number=Sing',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'nsubj',\n",
       "  'DEPS': '7:nsubj',\n",
       "  'MISC': '_'},\n",
       " {'ID': '4',\n",
       "  'FORM': 'är',\n",
       "  'LEMMA': 'vara',\n",
       "  'UPOS': 'AUX',\n",
       "  'XPOS': 'VB|PRS|AKT',\n",
       "  'FEATS': 'Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'cop',\n",
       "  'DEPS': '7:cop',\n",
       "  'MISC': '_'},\n",
       " {'ID': '5',\n",
       "  'FORM': 'av',\n",
       "  'LEMMA': 'av',\n",
       "  'UPOS': 'ADP',\n",
       "  'XPOS': 'PP',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'case',\n",
       "  'DEPS': '7:case',\n",
       "  'MISC': '_'},\n",
       " {'ID': '6',\n",
       "  'FORM': 'två',\n",
       "  'LEMMA': 'två',\n",
       "  'UPOS': 'NUM',\n",
       "  'XPOS': 'RG|NOM',\n",
       "  'FEATS': 'Case=Nom|NumType=Card',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'nummod',\n",
       "  'DEPS': '7:nummod',\n",
       "  'MISC': '_'},\n",
       " {'ID': '7',\n",
       "  'FORM': 'slag',\n",
       "  'LEMMA': 'slag',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|NEU|PLU|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Gender=Neut|Number=Plur',\n",
       "  'HEAD': '0',\n",
       "  'DEPREL': 'root',\n",
       "  'DEPS': '0:root',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " {'ID': '8',\n",
       "  'FORM': ':',\n",
       "  'LEMMA': ':',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': 'MID',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '7:punct',\n",
       "  'MISC': '_'},\n",
       " {'ID': '9',\n",
       "  'FORM': 'folkpension',\n",
       "  'LEMMA': 'folkpension',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|SIN|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Gender=Com|Number=Sing',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'appos',\n",
       "  'DEPS': '7:appos',\n",
       "  'MISC': '_'},\n",
       " {'ID': '10',\n",
       "  'FORM': 'och',\n",
       "  'LEMMA': 'och',\n",
       "  'UPOS': 'CCONJ',\n",
       "  'XPOS': 'KN',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '11',\n",
       "  'DEPREL': 'cc',\n",
       "  'DEPS': '11:cc',\n",
       "  'MISC': '_'},\n",
       " {'ID': '11',\n",
       "  'FORM': 'tilläggspension',\n",
       "  'LEMMA': 'tilläggspension',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|SIN|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Gender=Com|Number=Sing',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'appos',\n",
       "  'DEPS': '7:appos|9:conj:och',\n",
       "  'MISC': '_'},\n",
       " {'ID': '12',\n",
       "  'FORM': '(',\n",
       "  'LEMMA': '(',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': 'PAD',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '11:punct',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " {'ID': '13',\n",
       "  'FORM': 'ATP',\n",
       "  'LEMMA': 'ATP',\n",
       "  'UPOS': 'PROPN',\n",
       "  'XPOS': 'PM|NOM',\n",
       "  'FEATS': 'Case=Nom',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'appos',\n",
       "  'DEPS': '11:appos',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " {'ID': '14',\n",
       "  'FORM': ')',\n",
       "  'LEMMA': ')',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': 'PAD',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '11:punct',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " {'ID': '15',\n",
       "  'FORM': '.',\n",
       "  'LEMMA': '.',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': 'MAD',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '7:punct',\n",
       "  'MISC': '_'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_corpus_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1219"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(formatted_corpus_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file, formatted_corpus, column_names):\n",
    "    f_out = open(file, 'w', encoding='utf-8')\n",
    "    for sentence in formatted_corpus:\n",
    "        for row in sentence[1:]:\n",
    "            # print(row, flush=True)\n",
    "            for col in column_names[:-1]:\n",
    "                if col in row:\n",
    "                    f_out.write(row[col] + '\\t')\n",
    "                else:\n",
    "                    f_out.write('_\\t')\n",
    "            col = column_names[-1]\n",
    "            if col in row:\n",
    "                f_out.write(row[col] + '\\n')\n",
    "            else:\n",
    "                f_out.write('_\\n')\n",
    "        f_out.write('\\n')\n",
    "    #f_out.write('\\n')\n",
    "    f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file_name = 'out_sys'\n",
    "save(out_file_name, formatted_corpus_test_clean, column_names_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Once you have parsed the test set, you will measure the accuracy of your parser using the CoNLL evaluation script available here: http://universaldependencies.org/conll18/evaluation.html. Download it.\n",
    "2. You will run the evaluation in the cell below. Be sure to have the Python program in your folder.\n",
    "2. You will report your best score. You need to reach a _labelled attachment score_ (LAS) of 0.67 to pass this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7553614369141679"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import conll18_ud_eval\n",
    "system_ud_file = open(out_file_name, encoding='utf-8')\n",
    "system_ud = conll18_ud_eval.load_conllu(system_ud_file)\n",
    "\n",
    "gold_ud_file = open(path_sv_test, encoding='utf-8')\n",
    "gold_ud = conll18_ud_eval.load_conllu(gold_ud_file)\n",
    "\n",
    "las = conll18_ud_eval.evaluate(gold_ud, system_ud)['LAS'].f1\n",
    "las"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should you want to run the script in other experiments, just execute: `python conll18_ud_eval.py gold_file system_file`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the article: _Globally Normalized Transition-Based Neural Networks_ by Andor and al. (2016) [<a href=\"https://www.aclweb.org/anthology/P16-1231\">pdf</a>] and write in a few sentences how it relates to your work in this assignment.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have written all the code and run all the cells, fill in your ID and as well as the name of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "STIL_ID = [\"student1\", \"student2\"] # Write your stil ids as a list\n",
    "CURRENT_NOTEBOOK_PATH = os.path.join(os.getcwd(), \n",
    "                                     \"6-dependency_parsing_solution.ipynb\") # Write the name of your notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The submission code will send your answer. It consists of your best labeled attachment score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"las\": 0.7553614369141679}'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "ANSWER = json.dumps({'las': las\n",
    "                    })\n",
    "ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the moment of truth:\n",
    "1. Save your notebook and\n",
    "2. Run the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMISSION_NOTEBOOK_PATH = CURRENT_NOTEBOOK_PATH + \".submission.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "ASSIGNMENT = 6\n",
    "API_KEY = \"f581ba347babfea0b8f2c74a3a6776a7\"\n",
    "\n",
    "# Copy and compress current notebook\n",
    "with bz2.open(SUBMISSION_NOTEBOOK_PATH, mode=\"wb\") as fout:\n",
    "    with open(CURRENT_NOTEBOOK_PATH, \"rb\") as fin:\n",
    "        fout.write(fin.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'msg': None,\n",
       " 'status': 'correct',\n",
       " 'signature': '9f56a1ad60b611212a876d72a017ccc2d811aebef71828376d64dccc1c1c81bdc56b659cd17cb130e12c1baf5238334fb87d7427fa89e2dfcce3e367f5af6bea',\n",
       " 'submission_id': '7b5bfd6a-9dbe-4d6a-8adb-53cf32ab50ac'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "res = requests.post(\"https://vilde.cs.lth.se/edan20checker/submit\", \n",
    "                    files={\"notebook_file\": open(SUBMISSION_NOTEBOOK_PATH, \"rb\")}, \n",
    "                    data={\n",
    "                        \"stil_id\": STIL_ID,\n",
    "                        \"assignment\": ASSIGNMENT,\n",
    "                        \"answer\": ANSWER,\n",
    "                        \"api_key\": API_KEY,\n",
    "                    },\n",
    "               verify=True)\n",
    "\n",
    "# from IPython.display import display, JSON\n",
    "res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
